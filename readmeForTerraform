Best Practices
file terraform.tfvars best approach
in variable.tf file default varibale should be declared
output section for outputting values
always cross reference using resource_type_name.localname to have clean code
no repetition
maintain different folders for different tasks -keep functionality seperate
specify variable type in variable file to apply variable constraints- SORT OF VALIDATION kw:variable
varibale block must have desc, default, type
LOOP SYSTEM:
use count parameter for repeated creations
use list and map types for better variable assignment esp for az zones etc
use maps to map region to amiID
$count.index for using different names eg while creating iam users recursively
CONDITIONAL LOGIC SYSTEM:
creating resorces conditionaly - condition?trueval : falseval eg count = var.istest == true? 1 : 0
LOCAL VALUE USAGE:
assigning local values and using them to avoid repetion - esp for things like tags - kw: locals{common_tags
use local values in moderation or else they make code hard to read 
use it for mainly a single value which are likely to change in future
local values can also be used with conditional exp and var.var_names

FUNCTIONS:
built in fucntions only: function(arg1, arg2) 
to try functions as example : use teraaform console cmnd 
highly useful esp for DRY principle when used in integration with other functions

DATA SOURCES :
use this to fetch things like amiID which are frequently chnging and not good to hardcode kw:data {   filter {}}

DEBUG-LOGS:
set TF_LOG enviroemnet variable - options TRACE, DEBUG, INFO WARN ERROR
TRACE is the most verbose and default
eg export TF_LOG = TRACE 
to dump in a file - export TF_LOG_PATH = /tmp/terraform-crash.log --> this means export TRACE_LOG_PATH = pathname/filetoexxport.log

fmt command is for formatting
validate command is for validation unsupported arguments, undeclared variables


FOLDER STRUCTURE FOR LOAD ORDER:
variables.tf
provider.tf
terraform.tfvars
resource1.tf--eg ec2.tf
resource2.tf --eg iam-users.tf

REPEATABLE NESTED BLOCKS - DYANAMIC BLOCKS
for security grps esp ingress and egress rules for multiple ports naming convention --MANY BIG SECURITYUY RULES SO CODE blocks too much - no readability
specify a variable list of ports
  2nd -- kw
resource resorcename localname {
  dynamic "atrributename eg ingress"{
   for_each = list_var_name 
   content {
   from_port = ingress.value
   to_port = ingress.value
   protocol = 
   
   }

  }
}
or can use iterator kw
for_each listname
iterator = port
content {

from = port.value
} 


TAINTING :
to mark a resource as taint so as to destry n recreate it on next apply incase there have been a lot of manual changes not included in terraform
terrafrom taint aws_instance.myece2

SPLAT:
use * to get all -- here * means all

TERRAFORM GRAPH :
visual rep of configuration/eexec plan

terraform graph > filename.dot
graphviz is the package used to generate diagram

TERRAFORM PLAN on OUTPUT
terraform plan -out=path eg terraform plan -out = demopath --> this saves the plan as a binary file named as demopath in the same folder as the saved.tf file was
this is done to lock to a particular configuration only in the file. so that no unintended changes to the .tf infra is moved to the apply
now do terraform apply path


TERRAFORM OUTPUT CMND
to extract value of an output variable from tf state files
terraform output iam_names

TERRAFORM CONFIGURATIONS
terraffrom settings such as configuration usually put inside the terraform block
required_version setting to lock to specified versions only
specify exact required version for some cases like 0.12 needed explicity
required_providers block for the current module


to deal with larger infra - use smaller configurations with diff folders
NOT GOOD PRACTICES
with several infra components running a terraformplan will do a refresh for all theseveral resources and it iwll slow down operation

CONSTRUCTION MAP
ZIPMAP
2 lists one for keys and other for values and creates a map out of these
usecase: IAM users along wiht coressponding IAM arns needed in output
-refresh = false use this
-target = resource to only focus on 1 target

PROVISIONERS:
to install software on created webservers- configuration part of terrafrom; run code inside the server
local exec and remote exec are 2 type
REMOTE EXEC PROVISIONER:
connector block to allow terraform to connect to ec2 instances
this is inside provisioner block .. kw provisioner {inline{commands}}
coonection{type, user, private-key,host}


LOCAl EXEEC PROVISIONER:
to run code inside the directory where terraform is invoked
run ansible playbooks on the server after creation resource
kw provisioner "local-exec"{coomand =}

DESTROY TIME PROVISIONER:
runs when the resource within it is destroyed
kw: when = destroy
CREATION TIME PROVISIONER:
are run only when the resource is created
and when resource  creation fails : resource is marked as tainted

FAILURE SETTINGS:
kw: continue --> ignore apply time error and continue with the commnad of remote exec
and fail --> default , if failed tainted resource , to be destroyed with destroy comnd
on_failure = continue


MODULES: for DRY prinicple
use a separate module folder and a project folder under ur directory
in modules folder create that tf files(configuration) which are repeatable or reusable
for eg EC2 instances creation resource block code
this file is then called in kw:module block in project (folder)  files 
the path is mentioned while calling ( this causes the developer to jsut call alreDY written code for resource creation)
terraform init command to run inorider to initialize the module before plan

HARDCODING CHANGEABLE ATTRIS INTO MODULES NOT GOOD:
for attributes like instance_type which is changeable for every stage (QA, dev, prod) do not hardocde in module
use variable to define it in module with a default value
override the default variable value with explicitly defining it in ur project tf file

USE HARDOCDING TO AVOID UNINTNETIONAL CHANGES:
use hardcoding to avoid any person changing any value that is not required to change

TERRAFORM REGISTRY :
only verified modules to be used
use the code , copy and modify it in ur file named as registry-terraform.tf
terraform init will download the module with associated files as package in ur cli

TERRAFORM WORKSPACE:
for different workspaces like we have in windows or linux for different purposes
cmnd is terraform workspace - u can do terraform plan in a specific workspace after moving to specific workspace 
default is the name of current workspace unless u create new using the subcommand new
tfstate of default workspace in root directory
custom workspace created has the tfstate in subdirectory created inside ur directory by name of worksoace like dev, prod

SECURITY ASPECTS
never ever commit ur access keys to git 
even adding a file path to password attribute is bad cos this creates a tf state file where the password is still stored.
Source argument is used to tell the path where tofind  the source code foor the desired child module
ref aregument after ? in the git clone url tells the branch where to fetch the source code from
./or ../ indicates local path
files to add in gitignore file
.tfstate : contains sensitive data often
terrafrom.tfvars : same reason
.terraform: is large in size and recreated with terraform init cmnd
crash.log: to store logs when terraform crashes
to store .tfstate files use remote backend feature : eg s3 configured as remote bckend : using bacend.tf file with backend kw code block
STD (STATE storage & locking)and ENHANCED( state + remote) BACKENDS are 2 TYPES
