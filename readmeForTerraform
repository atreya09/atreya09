Best Practices
file terraform.tfvars best approach
in variable.tf file  varibale definition is present 
variable.tf or any variables in any.tf files takes highest precendece, so declare variable in .tfvars and define in .tfvars.
 as child module .tfvar files are treated as optional and root tfvars required and authoritative
Any overriding of the defaults that are set in your *.tfvar file, should be in a variables.tf file in the relevant directory of the module requiring the new variable, 
One thing to note though is that unless you use a separate directory structure and separate state files to handle each environment, you will overwrite any existing environment.
Terraform loads variables in the following order, with later sources taking precedence over earlier ones:
  @Environment variables
  @The tfvarsfile, if present.
  @The tfvars.jsonfile, if present.
  @Any *.auto.tfvars or *.auto.tfvars.json files, processed in lexical order of their filenames.
  @Any -var and -var-file options on the command line, in order they are provided. (This includes variables set by a Terraform Cloud workspace.)

The tfvars file extension is in the root folder of an environment to define values to variables, and the .tf uses modules to declare them,
however what complicates matters is that people have used tfvars files in modules and tf files in the root module.
So we use a *.tfvar file to load in defaults as they are automatically loaded without any additional command line option.




output section for outputting values
always cross reference using resource_type_name.localname to have clean code
no repetition
maintain different folders for different tasks -keep functionality seperate
specify variable type in variable file to apply variable constraints- SORT OF VALIDATION kw:variable
varibale block must have desc, default, type
LOOP SYSTEM:
use count parameter for repeated creations
use list and map types for better variable assignment esp for az zones etc
use maps to map region to amiID
$count.index for using different names eg while creating iam users recursively
CONDITIONAL LOGIC SYSTEM:
creating resorces conditionaly - condition?trueval : falseval eg count = var.istest == true? 1 : 0
LOCAL VALUE USAGE:
assigning local values and using them to avoid repetion - esp for things like tags - kw: locals{common_tags
use local values in moderation or else they make code hard to read 
use it for mainly a single value which are likely to change in future
local values can also be used with conditional exp and var.var_names

FUNCTIONS:
built in fucntions only: function(arg1, arg2) 
to try functions as example : use teraaform console cmnd 
highly useful esp for DRY principle when used in integration with other functions

DATA SOURCES :
use this to fetch things like amiID which are frequently chnging and not good to hardcode kw:data {   filter {}}

DEBUG-LOGS:
set TF_LOG enviroemnet variable - options TRACE, DEBUG, INFO WARN ERROR
TRACE is the most verbose and default
eg export TF_LOG = TRACE 
to dump in a file - export TF_LOG_PATH = /tmp/terraform-crash.log --> this means export TRACE_LOG_PATH = pathname/filetoexxport.log

fmt command is for formatting
validate command is for validation unsupported arguments, undeclared variables


FOLDER STRUCTURE FOR LOAD ORDER:
variables.tf
provider.tf
terraform.tfvars
resource1.tf--eg ec2.tf
resource2.tf --eg iam-users.tf

REPEATABLE NESTED BLOCKS - DYANAMIC BLOCKS
for security grps esp ingress and egress rules for multiple ports naming convention --MANY BIG SECURITYUY RULES SO CODE blocks too much - no readability
specify a variable list of ports
  2nd -- kw
resource resorcename localname {
  dynamic "atrributename eg ingress"{
   for_each = list_var_name 
   content {
   from_port = ingress.value
   to_port = ingress.value
   protocol = 
   
   }

  }
}
or can use iterator kw
for_each listname
iterator = port
content {

from = port.value
} 


TAINTING :
to mark a resource as taint so as to destry n recreate it on next apply incase there have been a lot of manual changes not included in terraform
terrafrom taint aws_instance.myece2

SPLAT:
use * to get all -- here * means all

TERRAFORM GRAPH :
visual rep of configuration/eexec plan

terraform graph > filename.dot
graphviz is the package used to generate diagram

TERRAFORM PLAN on OUTPUT
terraform plan -out=path eg terraform plan -out = demopath --> this saves the plan as a binary file named as demopath in the same folder as the saved.tf file was
this is done to lock to a particular configuration only in the file. so that no unintended changes to the .tf infra is moved to the apply
now do terraform apply path


TERRAFORM OUTPUT CMND
to extract value of an output variable from tf state files
terraform output iam_names

TERRAFORM CONFIGURATIONS
terraffrom settings such as configuration usually put inside the terraform block
required_version setting to lock to specified versions only
specify exact required version for some cases like 0.12 needed explicity
required_providers block for the current module


to deal with larger infra - use smaller configurations with diff folders
NOT GOOD PRACTICES
with several infra components running a terraformplan will do a refresh for all theseveral resources and it iwll slow down operation

CONSTRUCTION MAP
ZIPMAP
2 lists one for keys and other for values and creates a map out of these
usecase: IAM users along wiht coressponding IAM arns needed in output
-refresh = false use this
-target = resource to only focus on 1 target

PROVISIONERS:
to install software on created webservers- configuration part of terrafrom; run code inside the server
local exec and remote exec are 2 type
REMOTE EXEC PROVISIONER:
connector block to allow terraform to connect to ec2 instances
this is inside provisioner block .. kw provisioner {inline{commands}}
coonection{type, user, private-key,host}


LOCAl EXEEC PROVISIONER:
to run code inside the directory where terraform is invoked
run ansible playbooks on the server after creation resource
kw provisioner "local-exec"{coomand =}

DESTROY TIME PROVISIONER:
runs when the resource within it is destroyed
kw: when = destroy
CREATION TIME PROVISIONER:
are run only when the resource is created
and when resource  creation fails : resource is marked as tainted

FAILURE SETTINGS:
kw: continue --> ignore apply time error and continue with the commnad of remote exec
and fail --> default , if failed tainted resource , to be destroyed with destroy comnd
on_failure = continue


MODULES: for DRY prinicple
use a separate module folder and a project folder under ur directory
in modules folder create that tf files(configuration) which are repeatable or reusable
for eg EC2 instances creation resource block code
this file is then called in kw:module block in project (folder)  files 
the path is mentioned while calling ( this causes the developer to jsut call alreDY written code for resource creation)
terraform init command to run inorider to initialize the module before plan

HARDCODING CHANGEABLE ATTRIS INTO MODULES NOT GOOD:
for attributes like instance_type which is changeable for every stage (QA, dev, prod) do not hardocde in module
use variable to define it in module with a default value
override the default variable value with explicitly defining it in ur project tf file

USE HARDOCDING TO AVOID UNINTNETIONAL CHANGES:
use hardcoding to avoid any person changing any value that is not required to change

TERRAFORM REGISTRY :
only verified modules to be used
use the code , copy and modify it in ur file named as registry-terraform.tf
terraform init will download the module with associated files as package in ur cli

TERRAFORM WORKSPACE:
for different workspaces like we have in windows or linux for different purposes
cmnd is terraform workspace - u can do terraform plan in a specific workspace after moving to specific workspace 
default is the name of current workspace unless u create new using the subcommand new
tfstate of default workspace in root directory
custom workspace created has the tfstate in subdirectory created inside ur directory by name of worksoace like dev, prod

SECURITY ASPECTS
never ever commit ur access keys to git 
even adding a file path to password attribute is bad cos this creates a tf state file where the password is still stored.
Source argument is used to tell the path where tofind  the source code foor the desired child module
ref aregument after ? in the git clone url tells the branch where to fetch the source code from
./or ../ indicates local path
files to add in gitignore file
.tfstate : contains sensitive data often
terrafrom.tfvars : same reason
.terraform: is large in size and recreated with terraform init cmnd
crash.log: to store logs when terraform crashes
to store .tfstate files use remote backend feature : eg s3 configured as remote bckend : using bacend.tf file with backend kw code block
STD (STATE storage & locking)and ENHANCED( state + remote) BACKENDS are 2 TYPES

To inform terrafrom abt which backend to use. make a backend.tf file .. inside it 
put the backend block with acccess keys and secret keys to connect with aws 
and then run terraform init
this way the backend gets initiailized 
check that the tfstate file gets stored in ur remote backend(ie s3)

terraform plan locks the tfstate file to prevent simultaneous conflicts to tfstate file during write operation
remote backedn needs to supprt locking functionality inorder to avoid state file being corrupt due to simultaneous terraform plan
state locking with s3 is implemented with dyanodb-create table and add dyanidb table name as attribute in backend block
to modify state file use commands
list, mv, pull etc
lsit : list resource which are part of state file
move : to move items in state file, rename an existing resource without destroying or recreating it| best practice to rename a resource -- donot rename from .tf file , 
-> for above use mv cmnd terraform state mv |options| SOURCE(OLDNAME) DESTINATION(NEW NAME)
TERRAFORM PULL COMMAND : manually download and output the state from the remote state
push cmnd : to manually upload local state file to remote state: dont use this cmnd often
rm : remove items from state ; items not physically destroyed but no longer managed by terraform henceforth
show resourcename: to show attributes of a single provided resource

TERRAFORM IMPORT:
use this when manual changes done in console are to imported to aws so that henceforth the modifications to this resoirce can also be managed by IAc using terraform 
first create a tf file seeing the atrributes values form the console --> this is pre created manual infra currently not managed as IAC in teraform
eh terraform import resourcename.ec2 instance id from console -- > this command imports the state file and links it to the manualyy pre created ec2 instance without recreating it

SECURITY CONSIDERATIIONS:
dont use cred in providers.tf
for single provider and multiple configurations like region specific creation of resource use alias parameter - provider aws { alias: mumbai, region:us-east-1}
and in resource block - use the provider attribute - provider = aws/aliasname --> aws.mumbai
single provider ,multiple reosurces in  multiple accounts (that is multiple access keys) : use --profile parameter
specify profile = "profilenamefrom aws credential file or from aws for which access key belongs" in the reosurce block
use assume role block inside providers block -- specify role-arn and session-name
while working on a field containig senssitive parameter ; it is important to set the sensitive parameter as true in the schema
it will not encrypt the value in the state file 
prevent the fields value from showing up in the cli output


